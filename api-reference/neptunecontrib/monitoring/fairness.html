<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>neptunecontrib.monitoring.fairness API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>neptunecontrib.monitoring.fairness</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#
# Copyright (c) 2019, Neptune Labs Sp. z o.o.
#
# Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
from aif360.datasets import BinaryLabelDataset
from aif360.metrics.classification_metric import ClassificationMetric
import neptune
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from neptunecontrib.monitoring.utils import send_figure


def log_fairness_classification_metrics(y_true, y_pred_class, y_pred_score, sensitive_attributes,
                                        favorable_label, unfavorable_label,
                                        privileged_groups, unprivileged_groups,
                                        experiment=None, prefix=&#39;&#39;):
    &#34;&#34;&#34;Creates fairness metric charts, calculates fairness classification metrics and logs them to Neptune.

    Class-based metrics that are logged: &#39;true_positive_rate_difference&#39;,&#39;false_positive_rate_difference&#39;,
    &#39;false_omission_rate_difference&#39;, &#39;false_discovery_rate_difference&#39;, &#39;error_rate_difference&#39;,
    &#39;false_positive_rate_ratio&#39;, &#39;false_negative_rate_ratio&#39;, &#39;false_omission_rate_ratio&#39;,
    &#39;false_discovery_rate_ratio&#39;, &#39;error_rate_ratio&#39;, &#39;average_odds_difference&#39;, &#39;disparate_impact&#39;,
    &#39;statistical_parity_difference&#39;, &#39;equal_opportunity_difference&#39;, &#39;theil_index&#39;,
    &#39;between_group_theil_index&#39;, &#39;between_all_groups_theil_index&#39;, &#39;coefficient_of_variation&#39;,
    &#39;between_group_coefficient_of_variation&#39;, &#39;between_all_groups_coefficient_of_variation&#39;,
    &#39;generalized_entropy_index&#39;, &#39;between_group_generalized_entropy_index&#39;,
    &#39;between_all_groups_generalized_entropy_index&#39;

    Charts are logged to the &#39;metric_by_group&#39; channel: &#39;confusion matrix&#39;, &#39;TPR&#39;, &#39;TNR&#39;, &#39;FPR&#39;, &#39;FNR&#39;, &#39;PPV&#39;, &#39;NPV&#39;,
    &#39;FDR&#39;, &#39;FOR&#39;, &#39;ACC&#39;, &#39;error_rate&#39;, &#39;selection_rate&#39;, &#39;power&#39;, &#39;precision&#39;, &#39;recall&#39;,
    &#39;sensitivity&#39;, &#39;specificity&#39;.

    Args:
        y_true (array-like, shape (n_samples)): Ground truth (correct) target values.
        y_pred_class (array-like, shape (n_samples)): Class predictions with values 0 or 1.
        y_pred_score (array-like, shape (n_samples)): Class predictions with values from 0 to 1. Default None.
        sensitive_attributes (pandas.DataFrame, shape (n_samples, k)): datafame containing only sensitive columns.
        favorable_label (str or int): label that is favorable, brings positive value to a person being classified.
        unfavorable_label (str or int): label that is unfavorable, brings positive value to a person being classified.
        privileged_groups (dict): dictionary with column names and list of values for those columns that
           belong to the privileged groups.
        unprivileged_groups (dict): dictionary with column names and list of values for those columns that
           belong to the unprivileged groups.
        experiment(`neptune.experiments.Experiment`): Neptune experiment. Default is None.
        prefix(str): Prefix that will be added before metric name when logged to Neptune.

    Examples:
        Train the model and make predictions on test.
        Log metrics and performance curves to Neptune::

            import neptune
            from neptunecontrib.monitoring.fairness import log_fairness_classification_metrics

            neptune.init()
            with neptune.create_experiment():
                log_fairness_classification_metrics(y_true, y_pred_class, y_pred_score, test[[&#39;race&#39;]],
                                                    favorable_label=&#39;granted_parole&#39;,
                                                    unfavorable_label=&#39;not_granted_parole&#39;,
                                                    privileged_groups={&#39;race&#39;:[&#39;Caucasian&#39;]},
                                                    privileged_groups={&#39;race&#39;:[&#39;African-American&#39;,&#39;Hispanic]},
                                                    )

        Check out this experiment https://ui.neptune.ai/jakub-czakon/model-fairness/e/MOD-92/logs.

    &#34;&#34;&#34;
    _exp = experiment if experiment else neptune

    bias_info = {&#39;favorable_label&#39;: favorable_label,
                 &#39;unfavorable_label&#39;: unfavorable_label,
                 &#39;protected_columns&#39;: sensitive_attributes.columns.tolist()}

    privileged_info = _fmt_priveleged_info(privileged_groups, unprivileged_groups)

    ground_truth_test = _make_dataset(sensitive_attributes, y_true, **bias_info, **privileged_info)
    prediction_test = _make_dataset(sensitive_attributes, y_pred_class, y_pred_score, **bias_info, **privileged_info)

    clf_metric = ClassificationMetric(ground_truth_test, prediction_test, **privileged_info)

    _log_fairness_metrics(clf_metric, _exp, prefix)

    fig = _plot_confusion_matrix_by_group(clf_metric, figsize=(12, 4))
    plt.tight_layout()
    plt.close()
    send_figure(fig, channel_name=prefix + &#39;metrics_by_group&#39;)

    group_metrics = [&#39;TPR&#39;, &#39;TNR&#39;, &#39;FPR&#39;, &#39;FNR&#39;, &#39;PPV&#39;, &#39;NPV&#39;, &#39;FDR&#39;, &#39;FOR&#39;,
                     &#39;ACC&#39;, &#39;error_rate&#39;, &#39;selection_rate&#39;, &#39;power&#39;,
                     &#39;precision&#39;, &#39;recall&#39;, &#39;sensitivity&#39;, &#39;specificity&#39;]

    for metric_name in group_metrics:
        fig, ax = plt.subplots(figsize=(12, 8))
        _plot_performance_by_group(clf_metric, metric_name, ax)
        send_figure(fig, experiment=_exp, channel_name=prefix + &#39;metrics_by_group&#39;)
        plt.close()


def _make_dataset(features, labels, scores=None, protected_columns=None,
                  privileged_groups=None, unprivileged_groups=None,
                  favorable_label=None, unfavorable_label=None):
    df = features.copy()
    df[&#39;outcome&#39;] = labels

    if scores is not None:
        scores_names = &#39;scores&#39;
        df[scores_names] = scores
    else:
        scores_names = []

    dataset = BinaryLabelDataset(df=df, label_names=[&#39;outcome&#39;], scores_names=scores_names,
                                 protected_attribute_names=protected_columns,
                                 favorable_label=favorable_label, unfavorable_label=unfavorable_label,
                                 unprivileged_protected_attributes=unprivileged_groups)
    return dataset


def _fmt_priveleged_info(privileged_groups, unprivileged_groups):
    privileged_info = {}
    for name, group in zip([&#39;privileged_groups&#39;, &#39;unprivileged_groups&#39;],
                           [privileged_groups, unprivileged_groups]):
        privileged_info[name] = []
        for k, values in group.items():
            for v in values:
                privileged_info[name].append({k: v})

    return privileged_info


def _log_fairness_metrics(aif_metric, experiment, prefix):
    func_dict = {
        &#39;true_positive_rate_difference&#39;: aif_metric.true_positive_rate_difference,
        &#39;false_positive_rate_difference&#39;: aif_metric.false_positive_rate_difference,
        &#39;false_omission_rate_difference&#39;: aif_metric.false_omission_rate_difference,
        &#39;false_discovery_rate_difference&#39;: aif_metric.false_discovery_rate_difference,
        &#39;error_rate_difference&#39;: aif_metric.error_rate_difference,

        &#39;false_positive_rate_ratio&#39;: aif_metric.false_positive_rate_ratio,
        &#39;false_negative_rate_ratio&#39;: aif_metric.false_negative_rate_ratio,
        &#39;false_omission_rate_ratio&#39;: aif_metric.false_omission_rate_ratio,
        &#39;false_discovery_rate_ratio&#39;: aif_metric.false_discovery_rate_ratio,
        &#39;error_rate_ratio&#39;: aif_metric.error_rate_ratio,

        &#39;average_odds_difference&#39;: aif_metric.average_odds_difference,

        &#39;disparate_impact&#39;: aif_metric.disparate_impact,
        &#39;statistical_parity_difference&#39;: aif_metric.statistical_parity_difference,
        &#39;equal_opportunity_difference&#39;: aif_metric.equal_opportunity_difference,
        &#39;theil_index&#39;: aif_metric.theil_index,
        &#39;between_group_theil_index&#39;: aif_metric.between_group_theil_index,
        &#39;between_all_groups_theil_index&#39;: aif_metric.between_all_groups_theil_index,
        &#39;coefficient_of_variation&#39;: aif_metric.coefficient_of_variation,
        &#39;between_group_coefficient_of_variation&#39;: aif_metric.between_group_coefficient_of_variation,
        &#39;between_all_groups_coefficient_of_variation&#39;: aif_metric.between_all_groups_coefficient_of_variation,

        &#39;generalized_entropy_index&#39;: aif_metric.generalized_entropy_index,
        &#39;between_group_generalized_entropy_index&#39;: aif_metric.between_group_generalized_entropy_index,
        &#39;between_all_groups_generalized_entropy_index&#39;: aif_metric.between_all_groups_generalized_entropy_index}

    for name, func in func_dict.items():
        score = func()
        experiment.log_metric(prefix + name, score)


def _plot_confusion_matrix_by_group(aif_metric, figsize=None):
    if not figsize:
        figsize = (18, 4)

    cmap = plt.get_cmap(&#39;Blues&#39;)
    fig, axs = plt.subplots(1, 3, figsize=figsize)

    axs[0].set_title(&#39;all&#39;)
    cm = _format_aif360_to_sklearn(aif_metric.binary_confusion_matrix(privileged=None))
    sns.heatmap(cm, cmap=cmap, annot=True, fmt=&#39;g&#39;, ax=axs[0])
    axs[0].set_xlabel(&#39;predicted values&#39;)
    axs[0].set_ylabel(&#39;actual values&#39;)

    axs[1].set_title(&#39;privileged&#39;)
    cm = _format_aif360_to_sklearn(aif_metric.binary_confusion_matrix(privileged=True))
    sns.heatmap(cm, cmap=cmap, annot=True, fmt=&#39;g&#39;, ax=axs[1])
    axs[1].set_xlabel(&#39;predicted values&#39;)
    axs[1].set_ylabel(&#39;actual values&#39;)

    axs[2].set_title(&#39;unprivileged&#39;)
    cm = _format_aif360_to_sklearn(aif_metric.binary_confusion_matrix(privileged=False))
    sns.heatmap(cm, cmap=cmap, annot=True, fmt=&#39;g&#39;, ax=axs[2])
    axs[2].set_xlabel(&#39;predicted values&#39;)
    axs[2].set_ylabel(&#39;actual values&#39;)
    return fig


def _plot_performance_by_group(aif_metric, metric_name, ax=None):
    performance_metrics = [&#39;TPR&#39;, &#39;TNR&#39;, &#39;FPR&#39;, &#39;FNR&#39;, &#39;PPV&#39;, &#39;NPV&#39;, &#39;FDR&#39;, &#39;FOR&#39;, &#39;ACC&#39;]

    func_dict = {&#39;selection_rate&#39;: lambda x: aif_metric.selection_rate(privileged=x),
                 &#39;precision&#39;: lambda x: aif_metric.precision(privileged=x),
                 &#39;recall&#39;: lambda x: aif_metric.recall(privileged=x),
                 &#39;sensitivity&#39;: lambda x: aif_metric.sensitivity(privileged=x),
                 &#39;specificity&#39;: lambda x: aif_metric.specificity(privileged=x),
                 &#39;power&#39;: lambda x: aif_metric.power(privileged=x),
                 &#39;error_rate&#39;: lambda x: aif_metric.error_rate(privileged=x)}

    if not ax:
        _, ax = plt.subplots()

    if metric_name in performance_metrics:
        metric_func = lambda x: aif_metric.performance_measures(privileged=x)[metric_name]
    elif metric_name in func_dict.keys():
        metric_func = func_dict[metric_name]
    else:
        raise NotImplementedError

    df = pd.DataFrame()
    df[&#39;Group&#39;] = [&#39;all&#39;, &#39;priveleged&#39;, &#39;unpriveleged&#39;]
    df[metric_name] = [metric_func(group) for group in [None, True, False]]

    sns.barplot(x=&#39;Group&#39;, y=metric_name, data=df, ax=ax)
    ax.set_title(&#39;{} by group&#39;.format(metric_name))
    ax.set_xlabel(None)

    _add_annotations(ax)


def _add_annotations(ax):
    for p in ax.patches:
        ax.annotate(format(p.get_height(), &#39;.3f&#39;),
                    (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha=&#39;center&#39;, va=&#39;center&#39;,
                    xytext=(0, -10), textcoords=&#39;offset points&#39;)


def _format_aif360_to_sklearn(aif360_mat):
    return np.array([[aif360_mat[&#39;TN&#39;], aif360_mat[&#39;FP&#39;]],
                     [aif360_mat[&#39;FN&#39;], aif360_mat[&#39;TP&#39;]]])</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="neptunecontrib.monitoring.fairness.log_fairness_classification_metrics"><code class="name flex">
<span>def <span class="ident">log_fairness_classification_metrics</span></span>(<span>y_true, y_pred_class, y_pred_score, sensitive_attributes, favorable_label, unfavorable_label, privileged_groups, unprivileged_groups, experiment=None, prefix='')</span>
</code></dt>
<dd>
<div class="desc"><p>Creates fairness metric charts, calculates fairness classification metrics and logs them to Neptune.</p>
<p>Class-based metrics that are logged: 'true_positive_rate_difference','false_positive_rate_difference',
'false_omission_rate_difference', 'false_discovery_rate_difference', 'error_rate_difference',
'false_positive_rate_ratio', 'false_negative_rate_ratio', 'false_omission_rate_ratio',
'false_discovery_rate_ratio', 'error_rate_ratio', 'average_odds_difference', 'disparate_impact',
'statistical_parity_difference', 'equal_opportunity_difference', 'theil_index',
'between_group_theil_index', 'between_all_groups_theil_index', 'coefficient_of_variation',
'between_group_coefficient_of_variation', 'between_all_groups_coefficient_of_variation',
'generalized_entropy_index', 'between_group_generalized_entropy_index',
'between_all_groups_generalized_entropy_index'</p>
<p>Charts are logged to the 'metric_by_group' channel: 'confusion matrix', 'TPR', 'TNR', 'FPR', 'FNR', 'PPV', 'NPV',
'FDR', 'FOR', 'ACC', 'error_rate', 'selection_rate', 'power', 'precision', 'recall',
'sensitivity', 'specificity'.</p>
<h2 id="args">Args</h2>
<dl>
<dt>y_true (array-like, shape (n_samples)): Ground truth (correct) target values.</dt>
<dt>y_pred_class (array-like, shape (n_samples)): Class predictions with values 0 or 1.</dt>
<dt>y_pred_score (array-like, shape (n_samples)): Class predictions with values from 0 to 1. Default None.</dt>
<dt>sensitive_attributes (pandas.DataFrame, shape (n_samples, k)): datafame containing only sensitive columns.</dt>
<dt><strong><code>favorable_label</code></strong> :&ensp;<code>str</code> or <code>int</code></dt>
<dd>label that is favorable, brings positive value to a person being classified.</dd>
<dt><strong><code>unfavorable_label</code></strong> :&ensp;<code>str</code> or <code>int</code></dt>
<dd>label that is unfavorable, brings positive value to a person being classified.</dd>
<dt><strong><code>privileged_groups</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary with column names and list of values for those columns that
belong to the privileged groups.</dd>
<dt><strong><code>unprivileged_groups</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary with column names and list of values for those columns that
belong to the unprivileged groups.</dd>
</dl>
<p>experiment(<code>neptune.experiments.Experiment</code>): Neptune experiment. Default is None.
prefix(str): Prefix that will be added before metric name when logged to Neptune.</p>
<h2 id="examples">Examples</h2>
<p>Train the model and make predictions on test.
Log metrics and performance curves to Neptune::</p>
<pre><code>import neptune
from neptunecontrib.monitoring.fairness import log_fairness_classification_metrics

neptune.init()
with neptune.create_experiment():
    log_fairness_classification_metrics(y_true, y_pred_class, y_pred_score, test[['race']],
                                        favorable_label='granted_parole',
                                        unfavorable_label='not_granted_parole',
                                        privileged_groups={'race':['Caucasian']},
                                        privileged_groups={'race':['African-American','Hispanic]},
                                        )
</code></pre>
<p>Check out this experiment <a href="https://ui.neptune.ai/jakub-czakon/model-fairness/e/MOD-92/logs.">https://ui.neptune.ai/jakub-czakon/model-fairness/e/MOD-92/logs.</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_fairness_classification_metrics(y_true, y_pred_class, y_pred_score, sensitive_attributes,
                                        favorable_label, unfavorable_label,
                                        privileged_groups, unprivileged_groups,
                                        experiment=None, prefix=&#39;&#39;):
    &#34;&#34;&#34;Creates fairness metric charts, calculates fairness classification metrics and logs them to Neptune.

    Class-based metrics that are logged: &#39;true_positive_rate_difference&#39;,&#39;false_positive_rate_difference&#39;,
    &#39;false_omission_rate_difference&#39;, &#39;false_discovery_rate_difference&#39;, &#39;error_rate_difference&#39;,
    &#39;false_positive_rate_ratio&#39;, &#39;false_negative_rate_ratio&#39;, &#39;false_omission_rate_ratio&#39;,
    &#39;false_discovery_rate_ratio&#39;, &#39;error_rate_ratio&#39;, &#39;average_odds_difference&#39;, &#39;disparate_impact&#39;,
    &#39;statistical_parity_difference&#39;, &#39;equal_opportunity_difference&#39;, &#39;theil_index&#39;,
    &#39;between_group_theil_index&#39;, &#39;between_all_groups_theil_index&#39;, &#39;coefficient_of_variation&#39;,
    &#39;between_group_coefficient_of_variation&#39;, &#39;between_all_groups_coefficient_of_variation&#39;,
    &#39;generalized_entropy_index&#39;, &#39;between_group_generalized_entropy_index&#39;,
    &#39;between_all_groups_generalized_entropy_index&#39;

    Charts are logged to the &#39;metric_by_group&#39; channel: &#39;confusion matrix&#39;, &#39;TPR&#39;, &#39;TNR&#39;, &#39;FPR&#39;, &#39;FNR&#39;, &#39;PPV&#39;, &#39;NPV&#39;,
    &#39;FDR&#39;, &#39;FOR&#39;, &#39;ACC&#39;, &#39;error_rate&#39;, &#39;selection_rate&#39;, &#39;power&#39;, &#39;precision&#39;, &#39;recall&#39;,
    &#39;sensitivity&#39;, &#39;specificity&#39;.

    Args:
        y_true (array-like, shape (n_samples)): Ground truth (correct) target values.
        y_pred_class (array-like, shape (n_samples)): Class predictions with values 0 or 1.
        y_pred_score (array-like, shape (n_samples)): Class predictions with values from 0 to 1. Default None.
        sensitive_attributes (pandas.DataFrame, shape (n_samples, k)): datafame containing only sensitive columns.
        favorable_label (str or int): label that is favorable, brings positive value to a person being classified.
        unfavorable_label (str or int): label that is unfavorable, brings positive value to a person being classified.
        privileged_groups (dict): dictionary with column names and list of values for those columns that
           belong to the privileged groups.
        unprivileged_groups (dict): dictionary with column names and list of values for those columns that
           belong to the unprivileged groups.
        experiment(`neptune.experiments.Experiment`): Neptune experiment. Default is None.
        prefix(str): Prefix that will be added before metric name when logged to Neptune.

    Examples:
        Train the model and make predictions on test.
        Log metrics and performance curves to Neptune::

            import neptune
            from neptunecontrib.monitoring.fairness import log_fairness_classification_metrics

            neptune.init()
            with neptune.create_experiment():
                log_fairness_classification_metrics(y_true, y_pred_class, y_pred_score, test[[&#39;race&#39;]],
                                                    favorable_label=&#39;granted_parole&#39;,
                                                    unfavorable_label=&#39;not_granted_parole&#39;,
                                                    privileged_groups={&#39;race&#39;:[&#39;Caucasian&#39;]},
                                                    privileged_groups={&#39;race&#39;:[&#39;African-American&#39;,&#39;Hispanic]},
                                                    )

        Check out this experiment https://ui.neptune.ai/jakub-czakon/model-fairness/e/MOD-92/logs.

    &#34;&#34;&#34;
    _exp = experiment if experiment else neptune

    bias_info = {&#39;favorable_label&#39;: favorable_label,
                 &#39;unfavorable_label&#39;: unfavorable_label,
                 &#39;protected_columns&#39;: sensitive_attributes.columns.tolist()}

    privileged_info = _fmt_priveleged_info(privileged_groups, unprivileged_groups)

    ground_truth_test = _make_dataset(sensitive_attributes, y_true, **bias_info, **privileged_info)
    prediction_test = _make_dataset(sensitive_attributes, y_pred_class, y_pred_score, **bias_info, **privileged_info)

    clf_metric = ClassificationMetric(ground_truth_test, prediction_test, **privileged_info)

    _log_fairness_metrics(clf_metric, _exp, prefix)

    fig = _plot_confusion_matrix_by_group(clf_metric, figsize=(12, 4))
    plt.tight_layout()
    plt.close()
    send_figure(fig, channel_name=prefix + &#39;metrics_by_group&#39;)

    group_metrics = [&#39;TPR&#39;, &#39;TNR&#39;, &#39;FPR&#39;, &#39;FNR&#39;, &#39;PPV&#39;, &#39;NPV&#39;, &#39;FDR&#39;, &#39;FOR&#39;,
                     &#39;ACC&#39;, &#39;error_rate&#39;, &#39;selection_rate&#39;, &#39;power&#39;,
                     &#39;precision&#39;, &#39;recall&#39;, &#39;sensitivity&#39;, &#39;specificity&#39;]

    for metric_name in group_metrics:
        fig, ax = plt.subplots(figsize=(12, 8))
        _plot_performance_by_group(clf_metric, metric_name, ax)
        send_figure(fig, experiment=_exp, channel_name=prefix + &#39;metrics_by_group&#39;)
        plt.close()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="neptunecontrib.monitoring" href="index.html">neptunecontrib.monitoring</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="neptunecontrib.monitoring.fairness.log_fairness_classification_metrics" href="#neptunecontrib.monitoring.fairness.log_fairness_classification_metrics">log_fairness_classification_metrics</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>